{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from tensorflow import set_random_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "from keras.layers import Dense, MaxPooling1D, Convolution1D, Dropout, Flatten, BatchNormalization\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seeds=42\n",
    "random.seed(seeds)\n",
    "seed(seeds)\n",
    "set_random_seed(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape is:  (182, 3140, 4)\n",
      "Validation shape is:  (46, 3140, 4)\n",
      "Test shape is:  (58, 3140, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load 3140 data that excludes the body\n",
    "X = np.load('../2_pipeline/3140-xyzl.npy')\n",
    "y = np.load('../2_pipeline/labels.npy')\n",
    "\n",
    "#split data into 1: train+validation set and 2: test set \n",
    "X_train_val, X_test, y_train_val, y_test = \\\n",
    "train_test_split(X, y, random_state=0, test_size=0.2)\n",
    "\n",
    "# split train+validation set into 1a) training and 1b) validation sets\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "train_test_split(X_train_val, y_train_val, random_state=1, test_size=0.2)\n",
    "\n",
    "#from keras.utils import to_categorical\n",
    "#y_test = to_categorical(y_test)\n",
    "#y_train = to_categorical(y_train)\n",
    "\n",
    "print('Training shape is: ', X_train.shape)\n",
    "print('Validation shape is: ', X_val.shape)\n",
    "print('Test shape is: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points=3140\n",
    "max_epochs=20\n",
    "batch_size=10\n",
    "dropout_rate = 0.5\n",
    "opt = 'adam'\n",
    "#opt = SGD(lr=0.0001, momentum=0.9)\n",
    "\n",
    "# Class weights\n",
    "class_weight = {0: 0.2,\n",
    "                1: 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "392/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 3140, 1570)        7850      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 1570)           0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1, 392)            615832    \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1, 196)            77028     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1, 1)              197       \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 700,907\n",
      "Trainable params: 700,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1570, input_shape=(num_points,4), activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=num_points))\n",
    "model.add(Dense(392, activation='relu'))\n",
    "model.add(Dense(196, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.add(Flatten())\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=max_epochs,\\\n",
    "                    shuffle=True, verbose=0, validation_data=(X_val, y_val),\\\n",
    "                    class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        36\n",
      "         1.0       0.38      1.00      0.55        22\n",
      "\n",
      "   micro avg       0.38      0.38      0.38        58\n",
      "   macro avg       0.19      0.50      0.27        58\n",
      "weighted avg       0.14      0.38      0.21        58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Classification Report\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    " \n",
    "# show a nicely formatted classification report\n",
    "print(\"[INFO] evaluating network...\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred.round()))\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# plot loss during training\n",
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "################################################################################\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print(\"\\n###################### Model Performance ############################\")\n",
    "print(\"\\n#####################################################################\")\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('\\nTrain: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "print(\"\\n#####################################################################\")\n",
    "################################################################################\n",
    "import matplotlib.pyplot as plt\n",
    "# plot loss during training\n",
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "################################################################################\n",
    "print(\"\\n#####################################################################\")\n",
    "# Create the confusion matrix\n",
    "ann_cm = confusion_matrix(y_true = y_test, y_pred = y_pred.round())\n",
    "print(\"\\nOur test confusion matrix yields: \")\n",
    "print(ann_cm)\n",
    "print(\"\\n#####################################################################\")\n",
    "\n",
    "#Classification report\n",
    "ann_report = classification_report(y_test, y_pred.round())\n",
    "print(\"\\nClassfication Report for test:\\n\", ann_report)\n",
    "print(\"\\n#####################################################################\")\n",
    "\n",
    "#Calculate AUC score\n",
    "ann_auc = roc_auc_score(y_test, y_pred.round())\n",
    "print(\"\\nOur testing AUC for ann is: \", ann_auc)\n",
    "\n",
    "# Calculate false positive and true positive rates\n",
    "fpr_ann, tpr_ann, thresholds_ann = roc_curve(y_test, y_pred.round())\n",
    "\n",
    "# Plot AUC \n",
    "plt.figure()\n",
    "plt.plot(fpr_ann, tpr_ann, color='purple', lw=2, label='ANN (area = {:.3f})'.format(ann_auc))\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"\\n#####################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aspDiVSrfrnW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TpO40yU8fx4p"
   },
   "source": [
    "# Model 4 - 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 50810,
     "status": "ok",
     "timestamp": 1555821937568,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "FQs_aQAyfxg4",
    "outputId": "326e5390-b763-4c0a-ce86-4cf2685a9317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# FOR GOOGLE COLAB\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2128,
     "status": "ok",
     "timestamp": 1555821942333,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "MmpTZGRrgOV0",
    "outputId": "1607958b-3c43-4b13-b1f0-0886d3b4fafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive\n"
     ]
    }
   ],
   "source": [
    "cd drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1156,
     "status": "ok",
     "timestamp": 1555821942969,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "eWHbfzuWgP0s",
    "outputId": "a8847849-bb47-4ab8-ae36-742afcbf4fc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "cd My Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1555821943835,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "ERyT9Lh_gSFY",
    "outputId": "ca2c260b-788e-49db-b0d7-9ea81f89aab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Dissertation/5_Code/1_code\n"
     ]
    }
   ],
   "source": [
    "cd Dissertation/5_Code/1_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2637,
     "status": "ok",
     "timestamp": 1555821945893,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "Yk5i0r8lgTXb",
    "outputId": "fd857475-871f-4365-84f3-c4c20bf00571"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DataPreparation.ipynb          Model5_ANN.ipynb\n",
      "'EDA&PreProcessing.ipynb'       my_model_16_16_16.h5\n",
      " keras-test.ipynb               original-voxel-model.ipynb\n",
      " Model1_PointNetFull.ipynb      PointNetBasic.ipynb\n",
      " Model2_PointNetBasic.ipynb     \u001b[0m\u001b[01;34mPy\u001b[0m/\n",
      " Model3_PointNetBasic_l.ipynb   \u001b[01;34m__pycache__\u001b[0m/\n",
      " Model4_3DCNN.ipynb             voxel-model.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQBm09HuQ_un"
   },
   "source": [
    "## 1. Set Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3721,
     "status": "ok",
     "timestamp": 1555821952339,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "1TIM8pTHQNlU",
    "outputId": "12757884-fc20-470d-f537-e877c4830105"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DtZsapx5RFuD"
   },
   "source": [
    "## 2. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4RkqooTgkBp"
   },
   "outputs": [],
   "source": [
    "# Install depedencies\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
    "from keras.layers import Dropout, Input, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, classification_report\n",
    "#from mlxtend.plotting import plot_confusion_matrix\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta, SGD, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import keras\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-3ctu05HDgz"
   },
   "source": [
    "## 3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2340,
     "status": "ok",
     "timestamp": 1555822361818,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "eUU1Ydk2HFJT",
    "outputId": "c449b1d2-b7b9-4daf-94a1-72d06f0f15c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the data...\n",
      "X training size is:  (182, 4096)\n",
      "y training size is:  (182,)\n",
      "\n",
      "X val size is:  (46, 4096)\n",
      "y val size is:  (46,)\n",
      "\n",
      "X test size is:  (58, 4096)\n",
      "y test size is:  (58,)\n"
     ]
    }
   ],
   "source": [
    "size = 16\n",
    "h,w,d = size,size,size\n",
    "\n",
    "if size == 16:\n",
    "    X = np.load('../2_pipeline/voxeldata_16.npy')\n",
    "else:\n",
    "    X = np.load('../2_pipeline/voxeldata_32.npy')\n",
    "y = np.load('../2_pipeline/labels.npy')\n",
    "\n",
    "#split the data\n",
    "print(\"Splitting the data...\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split data into 1: train+validation set and 2: test set \n",
    "X_train_val, X_test, y_train_val, y_test = \\\n",
    "train_test_split(X, y, random_state=0, test_size=0.2)\n",
    "\n",
    "# split train+validation set into 1a) training and 1b) validation sets\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "train_test_split(X_train_val, y_train_val, random_state=1, test_size=0.2)\n",
    "\n",
    "# Check train and test size\n",
    "print(\"X training size is: \", X_train.shape)\n",
    "print(\"y training size is: \", y_train.shape)\n",
    "print(\"\\nX val size is: \", X_val.shape)\n",
    "print(\"y val size is: \", y_val.shape)\n",
    "print(\"\\nX test size is: \", X_test.shape)\n",
    "print(\"y test size is: \", y_test.shape)\n",
    "\n",
    "x_train = X_train.reshape(X_train.shape[0], h, w, d,1)\n",
    "x_val = X_val.reshape(X_val.shape[0], h, w, d,1)\n",
    "x_test = X_test.reshape(X_test.shape[0], h, w, d,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hxzHg-yamDDC"
   },
   "source": [
    "## 4. Build 3D CNN\n",
    "Lets create the model architecture. The architecture is described below:\n",
    "\n",
    "Input and Output layers:\n",
    "\n",
    "* One Input layer with dimentions 16, 16, 16, 3\n",
    "* Output layer with dimensions 2\n",
    "\n",
    "Convolutions :\n",
    "* Apply 4 Convolutional layer with increasing order of filter size (standard size : 8, 16, 32, 64) and fixed kernel size = (3, 3, 3)\n",
    "* Apply 2 Max Pooling layers, one after 2nd convolutional layer and one after fourth convolutional layer.\n",
    "\n",
    "MLP architecture:\n",
    "* Batch normalization on convolutiona architecture\n",
    "* Dense layers with 2 layers followed by dropout to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2815,
     "status": "ok",
     "timestamp": 1555822362306,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "9ehreKDoq_30",
    "outputId": "64d530db-aa92-4452-e894-b4081d30fef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_57 (Conv3D)           (None, 14, 14, 14, 8)     224       \n",
      "_________________________________________________________________\n",
      "conv3d_58 (Conv3D)           (None, 12, 12, 12, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_29 (MaxPooling (None, 6, 6, 6, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_59 (Conv3D)           (None, 4, 4, 4, 32)       13856     \n",
      "_________________________________________________________________\n",
      "conv3d_60 (Conv3D)           (None, 2, 2, 2, 64)       55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_30 (MaxPooling (None, 1, 1, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 1, 1, 1, 64)       256       \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 4096)              266240    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 2,456,017\n",
      "Trainable params: 2,446,673\n",
      "Non-trainable params: 9,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "max_epochs = 25\n",
    "batch_size = 16 # 8 < 16 > 32 > 128\n",
    "#opt = Adadelta(lr=0.001)\n",
    "opt = Adam(lr=0.001, decay=0.7)\n",
    "dropout_rate=0.2\n",
    "\n",
    "#from keras.optimizers import SGD\n",
    "#opt = SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "# Class weights\n",
    "class_weight = {0: 0.3,\n",
    "                1: 0.7}\n",
    "\n",
    "model = Sequential()\n",
    "# Convolution layers\n",
    "model.add(Conv3D(filters=8, kernel_size=(3, 3, 3), activation='relu', input_shape=(h, w, d, 1)))\n",
    "model.add(Conv3D(filters=16, kernel_size=(3, 3, 3), activation='relu'))\n",
    "# Add max pooling to obtain the most informatic features\n",
    "model.add(MaxPool3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Convolution layers\n",
    "model.add(Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "# Add max pooling to obtain the most informatic features\n",
    "model.add(MaxPool3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "## perform batch normalization on the convolution outputs before feeding it to MLP architecture\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "\n",
    "## create an MLP architecture with dense layers : 4096 -> 512 -> 10\n",
    "## add dropouts to avoid overfitting / perform regularization\n",
    "model.add(Dense(units=(h*w*d), activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VgO-6wHt9hrD"
   },
   "source": [
    "## 5. Train model & Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################### Training Model ##############################\n",
      "Training...\n",
      "Train on 182 samples, validate on 46 samples\n",
      "Epoch 1/25\n",
      "182/182 [==============================] - 10s 54ms/step - loss: 0.4495 - acc: 0.5330 - val_loss: 1.4487 - val_acc: 0.4348\n",
      "Epoch 2/25\n",
      "182/182 [==============================] - 2s 13ms/step - loss: 0.2562 - acc: 0.6703 - val_loss: 1.1851 - val_acc: 0.4348\n",
      "Epoch 3/25\n",
      " 96/182 [==============>...............] - ETA: 1s - loss: 0.1809 - acc: 0.7500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-6a3c47d870d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m history = model.fit(x=x_train, y=y_train, batch_size=batch_size, \\\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     validation_data=(x_val, y_val), verbose=1)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n####################### Training Model ##############################\")\n",
    "print(\"Training...\")\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=batch_size, \\\n",
    "                    epochs=max_epochs, class_weight=class_weight, \\\n",
    "                    validation_data=(x_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###################### Model Performance ############################\n",
      "\n",
      "Train: 0.571, Test: 0.466\n",
      "\n",
      "#####################################################################\n",
      "\n",
      "Classfication Report for test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.22      0.34        36\n",
      "         1.0       0.40      0.86      0.55        22\n",
      "\n",
      "   micro avg       0.47      0.47      0.47        58\n",
      "   macro avg       0.57      0.54      0.45        58\n",
      "weighted avg       0.60      0.47      0.42        58\n",
      "\n",
      "\n",
      "#####################################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n###################### Model Performance ############################\")\n",
    "# Make predictions \n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\nTrain: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "print(\"\\n#####################################################################\")\n",
    "\n",
    "#Classification report\n",
    "report = classification_report(y_test, y_pred.round())\n",
    "print(\"\\nClassfication Report for test:\\n\", report)\n",
    "print(\"\\n#####################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1358
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14789,
     "status": "ok",
     "timestamp": 1555822374291,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "zAjS1XywuMh_",
    "outputId": "c9ddedf1-85a5-4d55-968d-0d839af41bc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our test confusion matrix yields: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7a72b4e80c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nOur test confusion matrix yields: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n#####################################################################\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_true = y_test, y_pred = y_pred.round())\n",
    "print(\"\\nOur test confusion matrix yields: \")\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()\n",
    "print(\"\\n#####################################################################\")\n",
    "\n",
    "\n",
    "# Plot AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "auc = auc(fpr, tpr)\n",
    "\n",
    "print(\"\\nThe AUC is\", auc)\n",
    "# Create AUC plot\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Keras (area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Keras (area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (zoomed in at top left)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"\\n#####################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2n94gKrmmuOm"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#model.save('my_model_16_16_16.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mh5J9UPXmveT"
   },
   "outputs": [],
   "source": [
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#model = load_model('my_model_16_16_16.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model4_3DCNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aspDiVSrfrnW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TpO40yU8fx4p"
   },
   "source": [
    "# Model 4 - 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 50810,
     "status": "ok",
     "timestamp": 1555821937568,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "FQs_aQAyfxg4",
    "outputId": "326e5390-b763-4c0a-ce86-4cf2685a9317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# FOR GOOGLE COLAB\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2128,
     "status": "ok",
     "timestamp": 1555821942333,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "MmpTZGRrgOV0",
    "outputId": "1607958b-3c43-4b13-b1f0-0886d3b4fafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive\n"
     ]
    }
   ],
   "source": [
    "cd drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1156,
     "status": "ok",
     "timestamp": 1555821942969,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "eWHbfzuWgP0s",
    "outputId": "a8847849-bb47-4ab8-ae36-742afcbf4fc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "cd My Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1555821943835,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "ERyT9Lh_gSFY",
    "outputId": "ca2c260b-788e-49db-b0d7-9ea81f89aab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Dissertation/5_Code/1_code\n"
     ]
    }
   ],
   "source": [
    "cd Dissertation/5_Code/1_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2637,
     "status": "ok",
     "timestamp": 1555821945893,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "Yk5i0r8lgTXb",
    "outputId": "fd857475-871f-4365-84f3-c4c20bf00571"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DataPreparation.ipynb          Model5_ANN.ipynb\n",
      "'EDA&PreProcessing.ipynb'       my_model_16_16_16.h5\n",
      " keras-test.ipynb               original-voxel-model.ipynb\n",
      " Model1_PointNetFull.ipynb      PointNetBasic.ipynb\n",
      " Model2_PointNetBasic.ipynb     \u001b[0m\u001b[01;34mPy\u001b[0m/\n",
      " Model3_PointNetBasic_l.ipynb   \u001b[01;34m__pycache__\u001b[0m/\n",
      " Model4_3DCNN.ipynb             voxel-model.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQBm09HuQ_un"
   },
   "source": [
    "## 1. Set Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3721,
     "status": "ok",
     "timestamp": 1555821952339,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "1TIM8pTHQNlU",
    "outputId": "12757884-fc20-470d-f537-e877c4830105"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DtZsapx5RFuD"
   },
   "source": [
    "## 2. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4RkqooTgkBp"
   },
   "outputs": [],
   "source": [
    "# Install depedencies\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
    "from keras.layers import Dropout, Input, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, classification_report\n",
    "#from mlxtend.plotting import plot_confusion_matrix\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta, SGD, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import keras\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-3ctu05HDgz"
   },
   "source": [
    "## 3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2340,
     "status": "ok",
     "timestamp": 1555822361818,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "eUU1Ydk2HFJT",
    "outputId": "c449b1d2-b7b9-4daf-94a1-72d06f0f15c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the data...\n",
      "X training size is:  (182, 4096)\n",
      "y training size is:  (182,)\n",
      "\n",
      "X val size is:  (46, 4096)\n",
      "y val size is:  (46,)\n",
      "\n",
      "X test size is:  (58, 4096)\n",
      "y test size is:  (58,)\n"
     ]
    }
   ],
   "source": [
    "size = 16\n",
    "h,w,d = size,size,size\n",
    "\n",
    "if size == 16:\n",
    "    X = np.load('../2_pipeline/voxeldata_16.npy')\n",
    "else:\n",
    "    X = np.load('../2_pipeline/voxeldata_32.npy')\n",
    "y = np.load('../2_pipeline/labels.npy')\n",
    "\n",
    "#split the data\n",
    "print(\"Splitting the data...\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split data into 1: train+validation set and 2: test set \n",
    "X_train_val, X_test, y_train_val, y_test = \\\n",
    "train_test_split(X, y, random_state=0, test_size=0.2)\n",
    "\n",
    "# split train+validation set into 1a) training and 1b) validation sets\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "train_test_split(X_train_val, y_train_val, random_state=1, test_size=0.2)\n",
    "\n",
    "# Check train and test size\n",
    "print(\"X training size is: \", X_train.shape)\n",
    "print(\"y training size is: \", y_train.shape)\n",
    "print(\"\\nX val size is: \", X_val.shape)\n",
    "print(\"y val size is: \", y_val.shape)\n",
    "print(\"\\nX test size is: \", X_test.shape)\n",
    "print(\"y test size is: \", y_test.shape)\n",
    "\n",
    "x_train = X_train.reshape(X_train.shape[0], h, w, d,1)\n",
    "x_val = X_val.reshape(X_val.shape[0], h, w, d,1)\n",
    "x_test = X_test.reshape(X_test.shape[0], h, w, d,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hxzHg-yamDDC"
   },
   "source": [
    "## 4. Build 3D CNN\n",
    "Lets create the model architecture. The architecture is described below:\n",
    "\n",
    "Input and Output layers:\n",
    "\n",
    "* One Input layer with dimentions 16, 16, 16, 3\n",
    "* Output layer with dimensions 2\n",
    "\n",
    "Convolutions :\n",
    "* Apply 4 Convolutional layer with increasing order of filter size (standard size : 8, 16, 32, 64) and fixed kernel size = (3, 3, 3)\n",
    "* Apply 2 Max Pooling layers, one after 2nd convolutional layer and one after fourth convolutional layer.\n",
    "\n",
    "MLP architecture:\n",
    "* Batch normalization on convolutiona architecture\n",
    "* Dense layers with 2 layers followed by dropout to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2815,
     "status": "ok",
     "timestamp": 1555822362306,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "9ehreKDoq_30",
    "outputId": "64d530db-aa92-4452-e894-b4081d30fef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 14, 14, 14, 8)     224       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 12, 12, 12, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 6, 6, 6, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 4, 4, 4, 32)       13856     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 2, 2, 2, 64)       55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 1, 1, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 1, 1, 64)       256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              266240    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 2,456,017\n",
      "Trainable params: 2,446,673\n",
      "Non-trainable params: 9,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "max_epochs = 250\n",
    "batch_size = 128\n",
    "#opt = Adadelta(lr=0.001)\n",
    "opt = Adam(lr=0.01, decay=0.7)\n",
    "dropout_rate=0.3\n",
    "\n",
    "#from keras.optimizers import SGD\n",
    "#opt = SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "# Class weights\n",
    "class_weight = {0: 0.2,\n",
    "                1: 0.8}\n",
    "\n",
    "model = Sequential()\n",
    "# Convolution layers\n",
    "model.add(Conv3D(filters=8, kernel_size=(3, 3, 3), activation='relu', input_shape=(h, w, d, 1)))\n",
    "model.add(Conv3D(filters=16, kernel_size=(3, 3, 3), activation='relu'))\n",
    "# Add max pooling to obtain the most informatic features\n",
    "model.add(MaxPool3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Convolution layers\n",
    "model.add(Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "# Add max pooling to obtain the most informatic features\n",
    "model.add(MaxPool3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "## perform batch normalization on the convolution outputs before feeding it to MLP architecture\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "\n",
    "## create an MLP architecture with dense layers : 4096 -> 512 -> 10\n",
    "## add dropouts to avoid overfitting / perform regularization\n",
    "model.add(Dense(units=(h*w*d), activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VgO-6wHt9hrD"
   },
   "source": [
    "## 5. Train model & Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1358
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14789,
     "status": "ok",
     "timestamp": 1555822374291,
     "user": {
      "displayName": "Phillip Hungerford",
      "photoUrl": "https://lh3.googleusercontent.com/-nSVU3pfDKvc/AAAAAAAAAAI/AAAAAAAA7nM/C4RLaD0imSQ/s64/photo.jpg",
      "userId": "04339632095681498586"
     },
     "user_tz": -600
    },
    "id": "zAjS1XywuMh_",
    "outputId": "c9ddedf1-85a5-4d55-968d-0d839af41bc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################### Training Model ##############################\n",
      "Training...\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n####################### Training Model ##############################\")\n",
    "print(\"Training...\")\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=max_epochs, class_weight=class_weight, validation_data=(x_val, y_val), verbose=0)\n",
    "print(\"\\n###################### Model Performance ############################\")\n",
    "# Make predictions \n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\nTrain: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "print(\"\\n#####################################################################\")\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_true = y_test, y_pred = y_pred.round())\n",
    "print(\"\\nOur test confusion matrix yields: \")\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()\n",
    "print(\"\\n#####################################################################\")\n",
    "\n",
    "#Classification report\n",
    "report = classification_report(y_test, y_pred.round())\n",
    "print(\"\\nClassfication Report for test:\\n\", report)\n",
    "print(\"\\n#####################################################################\")\n",
    "\n",
    "# Plot AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "auc = auc(fpr, tpr)\n",
    "\n",
    "print(\"\\nThe AUC is\", auc)\n",
    "# Create AUC plot\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Keras (area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Keras (area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (zoomed in at top left)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"\\n#####################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2n94gKrmmuOm"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#model.save('my_model_16_16_16.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mh5J9UPXmveT"
   },
   "outputs": [],
   "source": [
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#model = load_model('my_model_16_16_16.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model4_3DCNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

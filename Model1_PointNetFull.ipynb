{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model1_PointNetFull.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philastotle/dissertation-pointnet/blob/master/Model1_PointNetFull.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "79QVhy4kI6_z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model 1 - PointNet Full Model with Transformation Networks (T-Net)\n",
        "\n",
        "## Prediction of radiotherapy plan violation from spatial arrangement of target and organ at risk structures using deep learning\n",
        "\n",
        "_By Phillip Hungerford,  University of New South Wales_"
      ]
    },
    {
      "metadata": {
        "id": "vQ38m44SJBVy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "6ccb37d1-6a8e-4ac0-b7c9-1e9a0fa51d42"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jUWyJ9S3JKPn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1aeeb7c5-4fe7-4088-ab8a-e078f3e052ed"
      },
      "cell_type": "code",
      "source": [
        "cd drive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TJg-ybzTJLbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0816a9c4-d18b-449d-d94f-1987a87d25e4"
      },
      "cell_type": "code",
      "source": [
        "cd My Drive"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DN7jGXPZJOJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7781d0d4-adc2-474f-bb56-8cc973d29961"
      },
      "cell_type": "code",
      "source": [
        "cd Dissertation/5_Code/1_code"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Dissertation/5_Code/1_code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eHj5mvU_JP8N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "626f24f9-eab2-4998-d67c-3c994ed21871"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 3D_medical_visualisation_script.py   my_model3140.h5\n",
            " best_NNEE.hdf5                       my_model3768.h5\n",
            " best_NN.hdf5                         my_model4096.h5\n",
            " data_prep.py                         original-voxel-model.ipynb\n",
            "'EDA&PreProcessing.ipynb'             plot.png\n",
            " keras-test.ipynb                     PointNetBasic.ipynb\n",
            " model_1024.h5                        \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n",
            "'Model1_PointNetFull (1).ipynb'       tf_util.py\n",
            " Model1_PointNetFull.ipynb            trainHistoryDict3768\n",
            " my_model10204D.h5                    train.py\n",
            " my_model1024xyzl.h5                  voxel-model.ipynb\n",
            " my_model_16_16_16.h5                 voxels.ipynb\n",
            " my_model20454D.h5                    weights.h5\n",
            " my_model31404D.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lvvn3Pf3JRm3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "\n",
        "# For Google Colab\n",
        "#!pip install open3d-python\n",
        "\n",
        "# for reading the ply files \n",
        "#from open3d import *\n",
        "import numpy as np\n",
        "\n",
        "# To time \n",
        "import time\n",
        "\n",
        "# For reading the labels\n",
        "import pandas as pd\n",
        "\n",
        "# Pointnet dependencies\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from numpy.random import seed\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Sequential\n",
        "from tensorflow import set_random_seed\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
        "from keras.layers import Dense, MaxPooling1D, Convolution1D, Dropout, Flatten, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seeds=42\n",
        "random.seed(seeds)\n",
        "seed(seeds)\n",
        "set_random_seed(seeds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-zlj5NwJYB-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c7dad543-72c6-437d-f6c0-55e49dad5942"
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "desired_points = 1024\n",
        "#X = downsample_dataset(data_points, desired_points)\n",
        "#np.save('../2_pipeline/prostate-no-nodes-'+ str(desired_points) +'.npy', X)\n",
        "X = np.load('../2_pipeline/prostate-no-nodes-1024.npy')\n",
        "#X = np.load('../2_pipeline/no-body-4096.npy')\n",
        "y = np.load('../2_pipeline/labels.npy')\n",
        "\n",
        "#split data into 1: train+validation set and 2: test set \n",
        "X_train_val, X_test, y_train_val, y_test = \\\n",
        "train_test_split(X, y, random_state=0, test_size=0.2)\n",
        "\n",
        "# split train+validation set into 1a) training and 1b) validation sets\n",
        "X_train, X_val, y_train, y_val = \\\n",
        "train_test_split(X_train_val, y_train_val, random_state=1, test_size=0.2)\n",
        "\n",
        "# Training set\n",
        "train_points_r = X_train\n",
        "train_labels_r = y_train\n",
        "\n",
        "\n",
        "# Test set\n",
        "test_points_r = X_test\n",
        "test_labels_r = y_test\n",
        "\n",
        "# label to categorical\n",
        "from keras.utils import to_categorical\n",
        "#y_test = to_categorical(y_test)\n",
        "#y_train = to_categorical(y_train)\n",
        "# Let's examine the data. \n",
        "\n",
        "print(\"Training shape: \", train_points_r.shape)\n",
        "print(\"Test shape: \\t\", test_points_r.shape)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training shape:  (182, 1024, 3)\n",
            "Test shape: \t (58, 1024, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "18c2JF-BJoHp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hyperparameter\n",
        "# number of points in each sample\n",
        "num_points = desired_points\n",
        "\n",
        "# number of categories\n",
        "k = 2\n",
        "\n",
        "# define optimizer\n",
        "opt = optimizers.Adam(lr=0.001, decay=0.7)\n",
        "\n",
        "max_epochs=250\n",
        "batch_size=32\n",
        "dropout_rate = 0.7\n",
        "\n",
        "# Class weights\n",
        "class_weight = {0: 0.2, 1: 0.8}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4GuH3UHCJ8gp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "c52d7bfe-2ab9-453d-895c-a01b69bb13aa"
      },
      "cell_type": "code",
      "source": [
        "### POINTNET ARCHITECTURE\n",
        "\n",
        "input_points = Input(shape=(num_points, 3))\n",
        "x = Convolution1D(64, 1, activation='relu', input_shape=(num_points, 3))(input_points)\n",
        "x = BatchNormalization()(x)\n",
        "x = Convolution1D(128, 1, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Convolution1D(1024, 1, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling1D(pool_size=num_points)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(9, weights=[np.zeros([256, 9]), np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32)])(x)\n",
        "input_T = Reshape((3, 3))(x)\n",
        "\n",
        "# For affine transformation need to matrix multiply\n",
        "\n",
        "\n",
        "def mat_mul(A, B):\n",
        "    return tf.matmul(A, B)\n",
        "\n",
        "\n",
        "# forward net\n",
        "g = Lambda(mat_mul, arguments={'B': input_T})(input_points)\n",
        "g = Convolution1D(64, 1, input_shape=(num_points, 3), activation='relu')(g)\n",
        "g = BatchNormalization()(g)\n",
        "g = Convolution1D(64, 1, input_shape=(num_points, 3), activation='relu')(g)\n",
        "g = BatchNormalization()(g)\n",
        "\n",
        "# feature transform net\n",
        "f = Convolution1D(64, 1, activation='relu')(g)\n",
        "f = BatchNormalization()(f)\n",
        "f = Convolution1D(128, 1, activation='relu')(f)\n",
        "f = BatchNormalization()(f)\n",
        "f = Convolution1D(1024, 1, activation='relu')(f)\n",
        "f = BatchNormalization()(f)\n",
        "f = MaxPooling1D(pool_size=num_points)(f)\n",
        "f = Dense(512, activation='relu')(f)\n",
        "f = BatchNormalization()(f)\n",
        "f = Dense(256, activation='relu')(f)\n",
        "f = BatchNormalization()(f)\n",
        "f = Dense(64 * 64, weights=[np.zeros([256, 64 * 64]), np.eye(64).flatten().astype(np.float32)])(f)\n",
        "feature_T = Reshape((64, 64))(f)\n",
        "\n",
        "\n",
        "# forward net\n",
        "g = Lambda(mat_mul, arguments={'B': feature_T})(g)\n",
        "g = Convolution1D(64, 1, activation='relu')(g)\n",
        "g = BatchNormalization()(g)\n",
        "g = Convolution1D(128, 1, activation='relu')(g)\n",
        "g = BatchNormalization()(g)\n",
        "g = Convolution1D(1024, 1, activation='relu')(g)\n",
        "g = BatchNormalization()(g)\n",
        "\n",
        "\n",
        "# global_feature\n",
        "global_feature = MaxPooling1D(pool_size=num_points)(g)\n",
        "\n",
        "\n",
        "# point_net_cls\n",
        "c = Dense(512, activation='relu')(global_feature)\n",
        "c = BatchNormalization()(c)\n",
        "c = Dropout(rate=dropout_rate)(c)\n",
        "c = Dense(256, activation='relu')(c)\n",
        "c = BatchNormalization()(c)\n",
        "c = Dropout(rate=dropout_rate)(c)\n",
        "c = Dense(1, activation='sigmoid')(c)\n",
        "prediction = Flatten()(c)\n",
        "\n",
        "\n",
        "# print the model summary\n",
        "model = Model(inputs=input_points, outputs=prediction)\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "# compile classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Rotate and jitter points\n",
        "def rotate_point_cloud(batch_data):\n",
        "    \"\"\" Randomly rotate the point clouds to augument the dataset\n",
        "        rotation is per shape based along up direction\n",
        "        Input:\n",
        "          BxNx3 array, original batch of point clouds\n",
        "        Return:\n",
        "          BxNx3 array, rotated batch of point clouds\n",
        "    \"\"\"\n",
        "    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n",
        "    for k in range(batch_data.shape[0]):\n",
        "        rotation_angle = np.random.uniform() * 2 * np.pi\n",
        "        cosval = np.cos(rotation_angle)\n",
        "        sinval = np.sin(rotation_angle)\n",
        "        rotation_matrix = np.array([[cosval, 0, sinval],\n",
        "                                    [0, 1, 0],\n",
        "                                    [-sinval, 0, cosval]])\n",
        "        shape_pc = batch_data[k, ...]\n",
        "        rotated_data[k, ...] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n",
        "    return rotated_data\n",
        "\n",
        "\n",
        "def jitter_point_cloud(batch_data, sigma=0.01, clip=0.05):\n",
        "    \"\"\" Randomly jitter points. jittering is per point.\n",
        "        Input:\n",
        "          BxNx3 array, original batch of point clouds\n",
        "        Return:\n",
        "          BxNx3 array, jittered batch of point clouds\n",
        "    \"\"\"\n",
        "    B, N, C = batch_data.shape\n",
        "    assert(clip > 0)\n",
        "    jittered_data = np.clip(sigma * np.random.randn(B, N, C), -1 * clip, clip)\n",
        "    jittered_data += batch_data\n",
        "    return jittered_data"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        (None, 1024, 3)           0         \n",
            "_________________________________________________________________\n",
            "lambda_23 (Lambda)           (None, 1024, 3)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_125 (Conv1D)          (None, 1024, 64)          256       \n",
            "_________________________________________________________________\n",
            "batch_normalization_193 (Bat (None, 1024, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv1d_126 (Conv1D)          (None, 1024, 64)          4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_194 (Bat (None, 1024, 64)          256       \n",
            "_________________________________________________________________\n",
            "lambda_24 (Lambda)           (None, 1024, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_130 (Conv1D)          (None, 1024, 64)          4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_200 (Bat (None, 1024, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv1d_131 (Conv1D)          (None, 1024, 128)         8320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_201 (Bat (None, 1024, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_132 (Conv1D)          (None, 1024, 1024)        132096    \n",
            "_________________________________________________________________\n",
            "batch_normalization_202 (Bat (None, 1024, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_36 (MaxPooling (None, 1, 1024)           0         \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            (None, 1, 512)            524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_203 (Bat (None, 1, 512)            2048      \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 1, 512)            0         \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            (None, 1, 256)            131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_204 (Bat (None, 1, 256)            1024      \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 1, 256)            0         \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 1, 1)              257       \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 813,825\n",
            "Trainable params: 809,601\n",
            "Non-trainable params: 4,224\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LqZZpeYWNkcl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 19638
        },
        "outputId": "9b191e5a-689f-42d2-9a97-23b461c0b5df"
      },
      "cell_type": "code",
      "source": [
        "# Fit model on training data\n",
        "for i in range(1,max_epochs+1):\n",
        "    # model.fit(train_points_r, Y_train, batch_size=32, epochs=1, shuffle=True, verbose=1)\n",
        "    # rotate and jitter the points\n",
        "    train_points_rotate = rotate_point_cloud(train_points_r)\n",
        "    train_points_jitter = jitter_point_cloud(train_points_rotate)\n",
        "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\\\n",
        "                    shuffle=True, verbose=1, validation_data=(X_val, y_val),\\\n",
        "                    class_weight=class_weight)\n",
        "    s = \"Current epoch is:\" + str(i)\n",
        "    print(s)\n",
        "    if i % 5 == 0:\n",
        "        score = model.evaluate(test_points_r, y_test, verbose=1)\n",
        "        print('Test loss: ', score[0])\n",
        "        print('Test accuracy: ', score[1])\n",
        "\n",
        "\n",
        "# ## 10. Evaluate the Model\n",
        "# score the model\n",
        "score = model.evaluate(test_points_r, y_test, verbose=1)\n",
        "print('Test loss: ', score[0])\n",
        "print('Test accuracy: ', score[1])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 12s 66ms/step - loss: 0.4621 - acc: 0.5659 - val_loss: 1.8577 - val_acc: 0.6739\n",
            "Current epoch is:1\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.4472 - acc: 0.5495 - val_loss: 3.2776 - val_acc: 0.6739\n",
            "Current epoch is:2\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.4474 - acc: 0.4945 - val_loss: 3.7113 - val_acc: 0.6739\n",
            "Current epoch is:3\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3955 - acc: 0.6099 - val_loss: 3.7045 - val_acc: 0.6739\n",
            "Current epoch is:4\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3440 - acc: 0.5989 - val_loss: 3.9929 - val_acc: 0.6739\n",
            "Current epoch is:5\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  3.88167666566783\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3667 - acc: 0.5440 - val_loss: 3.7729 - val_acc: 0.6739\n",
            "Current epoch is:6\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3942 - acc: 0.5604 - val_loss: 3.3664 - val_acc: 0.6739\n",
            "Current epoch is:7\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3343 - acc: 0.5824 - val_loss: 3.1472 - val_acc: 0.6739\n",
            "Current epoch is:8\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3542 - acc: 0.5495 - val_loss: 2.2583 - val_acc: 0.6739\n",
            "Current epoch is:9\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3161 - acc: 0.5879 - val_loss: 1.6840 - val_acc: 0.6739\n",
            "Current epoch is:10\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.9088586856578957\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3564 - acc: 0.5220 - val_loss: 2.2904 - val_acc: 0.6739\n",
            "Current epoch is:11\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3051 - acc: 0.5879 - val_loss: 1.8620 - val_acc: 0.6739\n",
            "Current epoch is:12\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2963 - acc: 0.5604 - val_loss: 1.5797 - val_acc: 0.6739\n",
            "Current epoch is:13\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2998 - acc: 0.5604 - val_loss: 1.2935 - val_acc: 0.6087\n",
            "Current epoch is:14\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3471 - acc: 0.5220 - val_loss: 1.3707 - val_acc: 0.6304\n",
            "Current epoch is:15\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.18056137808438\n",
            "Test accuracy:  0.6724137869374506\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2873 - acc: 0.6154 - val_loss: 1.2610 - val_acc: 0.6304\n",
            "Current epoch is:16\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3087 - acc: 0.5879 - val_loss: 1.1134 - val_acc: 0.6087\n",
            "Current epoch is:17\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3243 - acc: 0.5989 - val_loss: 1.0502 - val_acc: 0.6087\n",
            "Current epoch is:18\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2785 - acc: 0.6099 - val_loss: 1.0930 - val_acc: 0.6087\n",
            "Current epoch is:19\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2969 - acc: 0.5879 - val_loss: 1.5330 - val_acc: 0.6739\n",
            "Current epoch is:20\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.61789163227739\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2735 - acc: 0.6264 - val_loss: 1.7937 - val_acc: 0.6739\n",
            "Current epoch is:21\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3206 - acc: 0.5604 - val_loss: 1.9443 - val_acc: 0.6739\n",
            "Current epoch is:22\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2984 - acc: 0.5824 - val_loss: 1.7116 - val_acc: 0.6739\n",
            "Current epoch is:23\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2904 - acc: 0.5714 - val_loss: 1.4469 - val_acc: 0.6087\n",
            "Current epoch is:24\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2604 - acc: 0.6044 - val_loss: 1.3594 - val_acc: 0.6087\n",
            "Current epoch is:25\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.1089271553631486\n",
            "Test accuracy:  0.6551724220144337\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3062 - acc: 0.5989 - val_loss: 1.2098 - val_acc: 0.5435\n",
            "Current epoch is:26\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2542 - acc: 0.6209 - val_loss: 1.2223 - val_acc: 0.6087\n",
            "Current epoch is:27\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3051 - acc: 0.6099 - val_loss: 1.6015 - val_acc: 0.6522\n",
            "Current epoch is:28\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2361 - acc: 0.6593 - val_loss: 2.4355 - val_acc: 0.6739\n",
            "Current epoch is:29\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2713 - acc: 0.6319 - val_loss: 2.1811 - val_acc: 0.6739\n",
            "Current epoch is:30\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  2.3840043133702773\n",
            "Test accuracy:  0.6034482717514038\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2668 - acc: 0.6099 - val_loss: 3.0803 - val_acc: 0.6739\n",
            "Current epoch is:31\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2242 - acc: 0.6429 - val_loss: 2.3814 - val_acc: 0.6739\n",
            "Current epoch is:32\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2435 - acc: 0.6374 - val_loss: 1.8042 - val_acc: 0.6739\n",
            "Current epoch is:33\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2591 - acc: 0.6044 - val_loss: 1.6458 - val_acc: 0.6739\n",
            "Current epoch is:34\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2412 - acc: 0.6209 - val_loss: 1.5623 - val_acc: 0.6522\n",
            "Current epoch is:35\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.8552286460481842\n",
            "Test accuracy:  0.6034482717514038\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2837 - acc: 0.6209 - val_loss: 1.5187 - val_acc: 0.6522\n",
            "Current epoch is:36\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2290 - acc: 0.6374 - val_loss: 1.6074 - val_acc: 0.6739\n",
            "Current epoch is:37\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.3021 - acc: 0.5934 - val_loss: 1.5552 - val_acc: 0.6739\n",
            "Current epoch is:38\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2631 - acc: 0.6209 - val_loss: 1.7584 - val_acc: 0.6739\n",
            "Current epoch is:39\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2213 - acc: 0.6319 - val_loss: 1.8258 - val_acc: 0.6739\n",
            "Current epoch is:40\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.7813187262107586\n",
            "Test accuracy:  0.637931042704089\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2150 - acc: 0.6154 - val_loss: 1.6612 - val_acc: 0.6739\n",
            "Current epoch is:41\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2651 - acc: 0.6264 - val_loss: 1.3566 - val_acc: 0.6739\n",
            "Current epoch is:42\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2233 - acc: 0.6319 - val_loss: 1.1530 - val_acc: 0.6739\n",
            "Current epoch is:43\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2246 - acc: 0.6758 - val_loss: 1.1851 - val_acc: 0.6304\n",
            "Current epoch is:44\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2221 - acc: 0.6264 - val_loss: 1.1038 - val_acc: 0.6304\n",
            "Current epoch is:45\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.2283719120354488\n",
            "Test accuracy:  0.6724138013247786\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1966 - acc: 0.7033 - val_loss: 2.6601 - val_acc: 0.6739\n",
            "Current epoch is:46\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2193 - acc: 0.6813 - val_loss: 2.0438 - val_acc: 0.6739\n",
            "Current epoch is:47\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1903 - acc: 0.6923 - val_loss: 1.6782 - val_acc: 0.6739\n",
            "Current epoch is:48\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2193 - acc: 0.6868 - val_loss: 1.3291 - val_acc: 0.6739\n",
            "Current epoch is:49\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2030 - acc: 0.6868 - val_loss: 1.0531 - val_acc: 0.6739\n",
            "Current epoch is:50\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.2422082835230335\n",
            "Test accuracy:  0.6551724220144337\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1981 - acc: 0.6484 - val_loss: 1.1057 - val_acc: 0.6304\n",
            "Current epoch is:51\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1956 - acc: 0.6538 - val_loss: 0.8932 - val_acc: 0.6087\n",
            "Current epoch is:52\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2164 - acc: 0.6758 - val_loss: 3.2782 - val_acc: 0.3261\n",
            "Current epoch is:53\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2191 - acc: 0.6209 - val_loss: 1.2377 - val_acc: 0.4565\n",
            "Current epoch is:54\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1892 - acc: 0.7088 - val_loss: 0.9907 - val_acc: 0.5652\n",
            "Current epoch is:55\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  0.7776373891994871\n",
            "Test accuracy:  0.6551724076271057\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1984 - acc: 0.6923 - val_loss: 0.7959 - val_acc: 0.6087\n",
            "Current epoch is:56\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1834 - acc: 0.6813 - val_loss: 0.7199 - val_acc: 0.6304\n",
            "Current epoch is:57\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1804 - acc: 0.6758 - val_loss: 0.9941 - val_acc: 0.6087\n",
            "Current epoch is:58\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2363 - acc: 0.6538 - val_loss: 2.0471 - val_acc: 0.6739\n",
            "Current epoch is:59\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1800 - acc: 0.7253 - val_loss: 1.9416 - val_acc: 0.6739\n",
            "Current epoch is:60\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  2.0533231291277656\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1724 - acc: 0.7253 - val_loss: 1.3147 - val_acc: 0.6739\n",
            "Current epoch is:61\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1617 - acc: 0.7143 - val_loss: 0.9071 - val_acc: 0.6957\n",
            "Current epoch is:62\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1626 - acc: 0.6758 - val_loss: 0.9771 - val_acc: 0.6957\n",
            "Current epoch is:63\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1931 - acc: 0.6868 - val_loss: 2.7020 - val_acc: 0.6739\n",
            "Current epoch is:64\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1584 - acc: 0.7253 - val_loss: 1.3358 - val_acc: 0.6739\n",
            "Current epoch is:65\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.6813493967056274\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1638 - acc: 0.7363 - val_loss: 1.1040 - val_acc: 0.6957\n",
            "Current epoch is:66\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1887 - acc: 0.7308 - val_loss: 1.1901 - val_acc: 0.6957\n",
            "Current epoch is:67\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1924 - acc: 0.7253 - val_loss: 0.9965 - val_acc: 0.7174\n",
            "Current epoch is:68\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1498 - acc: 0.7637 - val_loss: 0.9216 - val_acc: 0.6522\n",
            "Current epoch is:69\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1532 - acc: 0.7143 - val_loss: 1.3177 - val_acc: 0.6739\n",
            "Current epoch is:70\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.7394495462549144\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1330 - acc: 0.7418 - val_loss: 1.8204 - val_acc: 0.6739\n",
            "Current epoch is:71\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1415 - acc: 0.7473 - val_loss: 1.6375 - val_acc: 0.6739\n",
            "Current epoch is:72\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1444 - acc: 0.7582 - val_loss: 1.3519 - val_acc: 0.6739\n",
            "Current epoch is:73\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1593 - acc: 0.7473 - val_loss: 1.1122 - val_acc: 0.6957\n",
            "Current epoch is:74\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1158 - acc: 0.8242 - val_loss: 0.8896 - val_acc: 0.6957\n",
            "Current epoch is:75\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.197027827131337\n",
            "Test accuracy:  0.586206892441059\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1150 - acc: 0.8022 - val_loss: 0.7538 - val_acc: 0.7391\n",
            "Current epoch is:76\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1130 - acc: 0.8132 - val_loss: 0.7939 - val_acc: 0.7609\n",
            "Current epoch is:77\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1335 - acc: 0.7527 - val_loss: 1.1921 - val_acc: 0.6739\n",
            "Current epoch is:78\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1026 - acc: 0.8187 - val_loss: 3.4958 - val_acc: 0.6739\n",
            "Current epoch is:79\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1387 - acc: 0.7637 - val_loss: 1.7117 - val_acc: 0.6739\n",
            "Current epoch is:80\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.9664316917287892\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1221 - acc: 0.8077 - val_loss: 1.3054 - val_acc: 0.6739\n",
            "Current epoch is:81\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.2114 - acc: 0.7418 - val_loss: 1.2976 - val_acc: 0.6957\n",
            "Current epoch is:82\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1280 - acc: 0.8077 - val_loss: 1.9042 - val_acc: 0.6739\n",
            "Current epoch is:83\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1307 - acc: 0.7912 - val_loss: 2.0063 - val_acc: 0.6739\n",
            "Current epoch is:84\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1359 - acc: 0.7582 - val_loss: 2.1727 - val_acc: 0.6739\n",
            "Current epoch is:85\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  2.735617547199644\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1139 - acc: 0.8022 - val_loss: 4.8121 - val_acc: 0.6739\n",
            "Current epoch is:86\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1160 - acc: 0.7912 - val_loss: 4.3373 - val_acc: 0.6739\n",
            "Current epoch is:87\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1077 - acc: 0.8187 - val_loss: 3.2827 - val_acc: 0.6739\n",
            "Current epoch is:88\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1174 - acc: 0.7967 - val_loss: 3.0002 - val_acc: 0.6739\n",
            "Current epoch is:89\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1238 - acc: 0.8187 - val_loss: 2.6051 - val_acc: 0.6739\n",
            "Current epoch is:90\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  3.0406489043400207\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0892 - acc: 0.8462 - val_loss: 1.8381 - val_acc: 0.6739\n",
            "Current epoch is:91\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1206 - acc: 0.8022 - val_loss: 1.3408 - val_acc: 0.6957\n",
            "Current epoch is:92\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0874 - acc: 0.8626 - val_loss: 1.5434 - val_acc: 0.6957\n",
            "Current epoch is:93\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1035 - acc: 0.8407 - val_loss: 1.3879 - val_acc: 0.6957\n",
            "Current epoch is:94\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1066 - acc: 0.8022 - val_loss: 1.5741 - val_acc: 0.6957\n",
            "Current epoch is:95\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.7971052136914483\n",
            "Test accuracy:  0.637931042704089\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0962 - acc: 0.8516 - val_loss: 1.2165 - val_acc: 0.6957\n",
            "Current epoch is:96\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0890 - acc: 0.8462 - val_loss: 1.5010 - val_acc: 0.6739\n",
            "Current epoch is:97\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0865 - acc: 0.8462 - val_loss: 1.6373 - val_acc: 0.6957\n",
            "Current epoch is:98\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0924 - acc: 0.8352 - val_loss: 1.2268 - val_acc: 0.6957\n",
            "Current epoch is:99\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0954 - acc: 0.8297 - val_loss: 1.1149 - val_acc: 0.7174\n",
            "Current epoch is:100\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.3657368832621082\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1048 - acc: 0.8571 - val_loss: 1.7485 - val_acc: 0.6957\n",
            "Current epoch is:101\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0968 - acc: 0.8462 - val_loss: 1.5457 - val_acc: 0.6957\n",
            "Current epoch is:102\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0942 - acc: 0.8626 - val_loss: 1.1367 - val_acc: 0.7174\n",
            "Current epoch is:103\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0799 - acc: 0.8626 - val_loss: 1.2009 - val_acc: 0.7391\n",
            "Current epoch is:104\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0742 - acc: 0.8681 - val_loss: 1.1026 - val_acc: 0.7391\n",
            "Current epoch is:105\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.7355539552096664\n",
            "Test accuracy:  0.6206896633937441\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0819 - acc: 0.8846 - val_loss: 1.0006 - val_acc: 0.6957\n",
            "Current epoch is:106\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0790 - acc: 0.9066 - val_loss: 1.1362 - val_acc: 0.6304\n",
            "Current epoch is:107\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0855 - acc: 0.8571 - val_loss: 1.3635 - val_acc: 0.6957\n",
            "Current epoch is:108\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0998 - acc: 0.8516 - val_loss: 0.8039 - val_acc: 0.6739\n",
            "Current epoch is:109\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1428 - acc: 0.8626 - val_loss: 1.6355 - val_acc: 0.5000\n",
            "Current epoch is:110\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.4397108842586648\n",
            "Test accuracy:  0.6034482717514038\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1370 - acc: 0.8022 - val_loss: 0.7871 - val_acc: 0.6957\n",
            "Current epoch is:111\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0858 - acc: 0.8626 - val_loss: 1.0491 - val_acc: 0.6522\n",
            "Current epoch is:112\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1278 - acc: 0.8132 - val_loss: 0.7386 - val_acc: 0.7174\n",
            "Current epoch is:113\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0832 - acc: 0.8791 - val_loss: 0.8738 - val_acc: 0.6957\n",
            "Current epoch is:114\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0721 - acc: 0.8846 - val_loss: 1.0958 - val_acc: 0.7174\n",
            "Current epoch is:115\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.7203870970627357\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0671 - acc: 0.8901 - val_loss: 1.0801 - val_acc: 0.6957\n",
            "Current epoch is:116\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0555 - acc: 0.9011 - val_loss: 1.0642 - val_acc: 0.6957\n",
            "Current epoch is:117\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0804 - acc: 0.9066 - val_loss: 0.9717 - val_acc: 0.6522\n",
            "Current epoch is:118\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0726 - acc: 0.8901 - val_loss: 1.0907 - val_acc: 0.6522\n",
            "Current epoch is:119\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0847 - acc: 0.8571 - val_loss: 0.8480 - val_acc: 0.7391\n",
            "Current epoch is:120\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.228462605640806\n",
            "Test accuracy:  0.6034482861387318\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0740 - acc: 0.9011 - val_loss: 1.3076 - val_acc: 0.7174\n",
            "Current epoch is:121\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0602 - acc: 0.9121 - val_loss: 1.1956 - val_acc: 0.7174\n",
            "Current epoch is:122\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0598 - acc: 0.9011 - val_loss: 0.8637 - val_acc: 0.7174\n",
            "Current epoch is:123\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0447 - acc: 0.9341 - val_loss: 0.6897 - val_acc: 0.7174\n",
            "Current epoch is:124\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0543 - acc: 0.9176 - val_loss: 0.7685 - val_acc: 0.7391\n",
            "Current epoch is:125\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  0.9083364708670254\n",
            "Test accuracy:  0.6896551662477953\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0606 - acc: 0.9286 - val_loss: 0.8948 - val_acc: 0.6522\n",
            "Current epoch is:126\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0425 - acc: 0.9011 - val_loss: 0.6234 - val_acc: 0.7391\n",
            "Current epoch is:127\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0342 - acc: 0.9670 - val_loss: 0.8163 - val_acc: 0.7174\n",
            "Current epoch is:128\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0343 - acc: 0.9560 - val_loss: 0.9132 - val_acc: 0.6522\n",
            "Current epoch is:129\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0526 - acc: 0.9231 - val_loss: 1.0401 - val_acc: 0.6739\n",
            "Current epoch is:130\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.1147927580208614\n",
            "Test accuracy:  0.7068965599454683\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0524 - acc: 0.9286 - val_loss: 0.7777 - val_acc: 0.7391\n",
            "Current epoch is:131\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0659 - acc: 0.9121 - val_loss: 0.9777 - val_acc: 0.6957\n",
            "Current epoch is:132\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0500 - acc: 0.9176 - val_loss: 0.9503 - val_acc: 0.6957\n",
            "Current epoch is:133\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0517 - acc: 0.9341 - val_loss: 0.7223 - val_acc: 0.6522\n",
            "Current epoch is:134\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0723 - acc: 0.8901 - val_loss: 1.4220 - val_acc: 0.6739\n",
            "Current epoch is:135\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.2981497378184879\n",
            "Test accuracy:  0.6724138013247786\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0989 - acc: 0.8571 - val_loss: 1.0941 - val_acc: 0.7391\n",
            "Current epoch is:136\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0999 - acc: 0.8626 - val_loss: 1.1578 - val_acc: 0.6522\n",
            "Current epoch is:137\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0926 - acc: 0.8407 - val_loss: 0.8936 - val_acc: 0.7391\n",
            "Current epoch is:138\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0945 - acc: 0.8901 - val_loss: 0.8945 - val_acc: 0.6739\n",
            "Current epoch is:139\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0618 - acc: 0.9011 - val_loss: 0.8361 - val_acc: 0.6522\n",
            "Current epoch is:140\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.1454794036931004\n",
            "Test accuracy:  0.637931042704089\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0711 - acc: 0.8956 - val_loss: 0.7411 - val_acc: 0.6087\n",
            "Current epoch is:141\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1327 - acc: 0.8407 - val_loss: 1.7412 - val_acc: 0.6087\n",
            "Current epoch is:142\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1075 - acc: 0.8407 - val_loss: 1.9813 - val_acc: 0.6957\n",
            "Current epoch is:143\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1108 - acc: 0.8571 - val_loss: 2.2419 - val_acc: 0.6739\n",
            "Current epoch is:144\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1169 - acc: 0.8297 - val_loss: 2.8748 - val_acc: 0.6739\n",
            "Current epoch is:145\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  3.5825805581849197\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0846 - acc: 0.8846 - val_loss: 2.7306 - val_acc: 0.6739\n",
            "Current epoch is:146\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0609 - acc: 0.8901 - val_loss: 2.2118 - val_acc: 0.6739\n",
            "Current epoch is:147\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0499 - acc: 0.9341 - val_loss: 1.9508 - val_acc: 0.6739\n",
            "Current epoch is:148\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0422 - acc: 0.9396 - val_loss: 1.9462 - val_acc: 0.6739\n",
            "Current epoch is:149\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0476 - acc: 0.9286 - val_loss: 2.7653 - val_acc: 0.6739\n",
            "Current epoch is:150\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  3.173243826833265\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0505 - acc: 0.9176 - val_loss: 3.0781 - val_acc: 0.6739\n",
            "Current epoch is:151\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0544 - acc: 0.9231 - val_loss: 2.7699 - val_acc: 0.6739\n",
            "Current epoch is:152\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0415 - acc: 0.9396 - val_loss: 1.8306 - val_acc: 0.6957\n",
            "Current epoch is:153\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0446 - acc: 0.9341 - val_loss: 1.7857 - val_acc: 0.6957\n",
            "Current epoch is:154\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0327 - acc: 0.9396 - val_loss: 1.8287 - val_acc: 0.6957\n",
            "Current epoch is:155\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  2.5212795898832123\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0425 - acc: 0.9341 - val_loss: 1.7197 - val_acc: 0.6957\n",
            "Current epoch is:156\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0566 - acc: 0.9176 - val_loss: 2.0573 - val_acc: 0.6957\n",
            "Current epoch is:157\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0516 - acc: 0.9231 - val_loss: 2.6116 - val_acc: 0.6739\n",
            "Current epoch is:158\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0498 - acc: 0.9396 - val_loss: 2.4515 - val_acc: 0.6739\n",
            "Current epoch is:159\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0651 - acc: 0.9176 - val_loss: 2.8801 - val_acc: 0.6957\n",
            "Current epoch is:160\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  4.046805513316188\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0526 - acc: 0.9231 - val_loss: 2.6653 - val_acc: 0.6957\n",
            "Current epoch is:161\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0656 - acc: 0.8956 - val_loss: 1.1594 - val_acc: 0.5652\n",
            "Current epoch is:162\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0552 - acc: 0.9560 - val_loss: 1.7106 - val_acc: 0.6087\n",
            "Current epoch is:163\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0655 - acc: 0.9121 - val_loss: 1.5363 - val_acc: 0.7174\n",
            "Current epoch is:164\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0696 - acc: 0.9176 - val_loss: 1.7742 - val_acc: 0.6957\n",
            "Current epoch is:165\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.8283868329278354\n",
            "Test accuracy:  0.637931042704089\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1306 - acc: 0.8407 - val_loss: 1.2884 - val_acc: 0.6087\n",
            "Current epoch is:166\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0829 - acc: 0.9121 - val_loss: 1.0043 - val_acc: 0.6522\n",
            "Current epoch is:167\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0434 - acc: 0.9451 - val_loss: 1.8393 - val_acc: 0.6087\n",
            "Current epoch is:168\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0526 - acc: 0.9176 - val_loss: 1.6155 - val_acc: 0.5870\n",
            "Current epoch is:169\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0710 - acc: 0.8901 - val_loss: 1.0817 - val_acc: 0.6304\n",
            "Current epoch is:170\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.2444820938439205\n",
            "Test accuracy:  0.6551724096824383\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0548 - acc: 0.9396 - val_loss: 1.0682 - val_acc: 0.5652\n",
            "Current epoch is:171\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0369 - acc: 0.9505 - val_loss: 1.0345 - val_acc: 0.6522\n",
            "Current epoch is:172\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0289 - acc: 0.9560 - val_loss: 0.9952 - val_acc: 0.6304\n",
            "Current epoch is:173\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0257 - acc: 0.9780 - val_loss: 1.0649 - val_acc: 0.6957\n",
            "Current epoch is:174\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0291 - acc: 0.9505 - val_loss: 1.0652 - val_acc: 0.7174\n",
            "Current epoch is:175\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.42925658719293\n",
            "Test accuracy:  0.637931042704089\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0182 - acc: 0.9725 - val_loss: 1.2865 - val_acc: 0.7174\n",
            "Current epoch is:176\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0221 - acc: 0.9780 - val_loss: 1.3342 - val_acc: 0.6522\n",
            "Current epoch is:177\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0173 - acc: 0.9725 - val_loss: 1.1890 - val_acc: 0.7174\n",
            "Current epoch is:178\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0209 - acc: 0.9780 - val_loss: 1.0932 - val_acc: 0.6087\n",
            "Current epoch is:179\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0287 - acc: 0.9615 - val_loss: 0.9800 - val_acc: 0.6739\n",
            "Current epoch is:180\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.4970513787762871\n",
            "Test accuracy:  0.6206896654490767\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0188 - acc: 0.9780 - val_loss: 1.1909 - val_acc: 0.6739\n",
            "Current epoch is:181\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0143 - acc: 0.9890 - val_loss: 1.4274 - val_acc: 0.6957\n",
            "Current epoch is:182\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 1.3453 - val_acc: 0.6522\n",
            "Current epoch is:183\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0131 - acc: 0.9725 - val_loss: 1.1810 - val_acc: 0.6522\n",
            "Current epoch is:184\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0228 - acc: 0.9835 - val_loss: 1.1969 - val_acc: 0.6522\n",
            "Current epoch is:185\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.5539743448125904\n",
            "Test accuracy:  0.586206906828387\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0252 - acc: 0.9615 - val_loss: 1.3528 - val_acc: 0.6957\n",
            "Current epoch is:186\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0188 - acc: 0.9615 - val_loss: 1.0947 - val_acc: 0.7174\n",
            "Current epoch is:187\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0573 - acc: 0.9286 - val_loss: 1.1232 - val_acc: 0.6957\n",
            "Current epoch is:188\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0137 - acc: 0.9780 - val_loss: 1.0641 - val_acc: 0.6739\n",
            "Current epoch is:189\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0282 - acc: 0.9560 - val_loss: 1.0970 - val_acc: 0.6522\n",
            "Current epoch is:190\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.3703742602775837\n",
            "Test accuracy:  0.6551724096824383\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0424 - acc: 0.9670 - val_loss: 0.8975 - val_acc: 0.6739\n",
            "Current epoch is:191\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0308 - acc: 0.9615 - val_loss: 1.5551 - val_acc: 0.5652\n",
            "Current epoch is:192\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0739 - acc: 0.8901 - val_loss: 1.4217 - val_acc: 0.6957\n",
            "Current epoch is:193\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0631 - acc: 0.9176 - val_loss: 2.0124 - val_acc: 0.6957\n",
            "Current epoch is:194\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0620 - acc: 0.9121 - val_loss: 2.0749 - val_acc: 0.5435\n",
            "Current epoch is:195\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.7021064881620735\n",
            "Test accuracy:  0.6379310283167609\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0416 - acc: 0.9286 - val_loss: 4.7143 - val_acc: 0.3913\n",
            "Current epoch is:196\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0711 - acc: 0.9066 - val_loss: 1.1357 - val_acc: 0.6957\n",
            "Current epoch is:197\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0407 - acc: 0.9505 - val_loss: 1.5254 - val_acc: 0.7391\n",
            "Current epoch is:198\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0375 - acc: 0.9615 - val_loss: 1.3229 - val_acc: 0.6957\n",
            "Current epoch is:199\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0340 - acc: 0.9615 - val_loss: 1.2224 - val_acc: 0.6087\n",
            "Current epoch is:200\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.3510937238561695\n",
            "Test accuracy:  0.5862068944963915\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0349 - acc: 0.9560 - val_loss: 1.7669 - val_acc: 0.5217\n",
            "Current epoch is:201\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0340 - acc: 0.9670 - val_loss: 1.2376 - val_acc: 0.6522\n",
            "Current epoch is:202\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0701 - acc: 0.9615 - val_loss: 1.0418 - val_acc: 0.6087\n",
            "Current epoch is:203\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0259 - acc: 0.9780 - val_loss: 1.4867 - val_acc: 0.6087\n",
            "Current epoch is:204\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0244 - acc: 0.9670 - val_loss: 1.5917 - val_acc: 0.5652\n",
            "Current epoch is:205\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  2.1143987630975656\n",
            "Test accuracy:  0.5517241379310345\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0231 - acc: 0.9725 - val_loss: 1.9956 - val_acc: 0.5870\n",
            "Current epoch is:206\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0129 - acc: 0.9945 - val_loss: 1.1158 - val_acc: 0.6304\n",
            "Current epoch is:207\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0242 - acc: 0.9780 - val_loss: 1.4237 - val_acc: 0.5870\n",
            "Current epoch is:208\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0346 - acc: 0.9615 - val_loss: 1.7699 - val_acc: 0.5217\n",
            "Current epoch is:209\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0213 - acc: 0.9780 - val_loss: 1.6305 - val_acc: 0.5870\n",
            "Current epoch is:210\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.573710005858849\n",
            "Test accuracy:  0.586206892441059\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0144 - acc: 0.9835 - val_loss: 1.2843 - val_acc: 0.6739\n",
            "Current epoch is:211\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0115 - acc: 0.9890 - val_loss: 0.8859 - val_acc: 0.7174\n",
            "Current epoch is:212\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0097 - acc: 0.9945 - val_loss: 0.9474 - val_acc: 0.6957\n",
            "Current epoch is:213\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0155 - acc: 0.9780 - val_loss: 1.1766 - val_acc: 0.6957\n",
            "Current epoch is:214\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0113 - acc: 0.9835 - val_loss: 0.9171 - val_acc: 0.6304\n",
            "Current epoch is:215\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.6424917188184014\n",
            "Test accuracy:  0.5517241379310345\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0339 - acc: 0.9615 - val_loss: 1.6729 - val_acc: 0.6304\n",
            "Current epoch is:216\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0652 - acc: 0.9451 - val_loss: 1.3987 - val_acc: 0.7174\n",
            "Current epoch is:217\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0891 - acc: 0.9066 - val_loss: 1.9064 - val_acc: 0.5652\n",
            "Current epoch is:218\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0895 - acc: 0.8791 - val_loss: 5.1212 - val_acc: 0.4130\n",
            "Current epoch is:219\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0905 - acc: 0.8956 - val_loss: 1.7090 - val_acc: 0.6304\n",
            "Current epoch is:220\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  2.409483843836291\n",
            "Test accuracy:  0.46551724548997553\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0897 - acc: 0.9121 - val_loss: 1.8068 - val_acc: 0.7174\n",
            "Current epoch is:221\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1326 - acc: 0.8516 - val_loss: 1.3329 - val_acc: 0.6957\n",
            "Current epoch is:222\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.1092 - acc: 0.8791 - val_loss: 1.8925 - val_acc: 0.6087\n",
            "Current epoch is:223\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0711 - acc: 0.8956 - val_loss: 1.0074 - val_acc: 0.6957\n",
            "Current epoch is:224\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0577 - acc: 0.9066 - val_loss: 5.0787 - val_acc: 0.6739\n",
            "Current epoch is:225\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  6.032409191131592\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0827 - acc: 0.9121 - val_loss: 5.2559 - val_acc: 0.6739\n",
            "Current epoch is:226\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0856 - acc: 0.8681 - val_loss: 3.6343 - val_acc: 0.6739\n",
            "Current epoch is:227\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0730 - acc: 0.9231 - val_loss: 4.2488 - val_acc: 0.6739\n",
            "Current epoch is:228\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0786 - acc: 0.9176 - val_loss: 4.2813 - val_acc: 0.6739\n",
            "Current epoch is:229\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0736 - acc: 0.9231 - val_loss: 4.2793 - val_acc: 0.6739\n",
            "Current epoch is:230\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  4.95001325936153\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0581 - acc: 0.9176 - val_loss: 4.4193 - val_acc: 0.6739\n",
            "Current epoch is:231\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0524 - acc: 0.9505 - val_loss: 4.0795 - val_acc: 0.6739\n",
            "Current epoch is:232\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0349 - acc: 0.9451 - val_loss: 3.6521 - val_acc: 0.6739\n",
            "Current epoch is:233\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0147 - acc: 0.9780 - val_loss: 3.1870 - val_acc: 0.6739\n",
            "Current epoch is:234\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0344 - acc: 0.9451 - val_loss: 2.6419 - val_acc: 0.6739\n",
            "Current epoch is:235\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  3.401933480953348\n",
            "Test accuracy:  0.6206896510617487\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0295 - acc: 0.9670 - val_loss: 2.8729 - val_acc: 0.6957\n",
            "Current epoch is:236\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0339 - acc: 0.9505 - val_loss: 3.2197 - val_acc: 0.6739\n",
            "Current epoch is:237\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0151 - acc: 0.9890 - val_loss: 2.9641 - val_acc: 0.6739\n",
            "Current epoch is:238\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0186 - acc: 0.9835 - val_loss: 2.6196 - val_acc: 0.6957\n",
            "Current epoch is:239\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0166 - acc: 0.9835 - val_loss: 1.9455 - val_acc: 0.7174\n",
            "Current epoch is:240\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  2.397847397574063\n",
            "Test accuracy:  0.586206906828387\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0286 - acc: 0.9615 - val_loss: 1.9297 - val_acc: 0.6739\n",
            "Current epoch is:241\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0616 - acc: 0.9341 - val_loss: 2.0578 - val_acc: 0.7174\n",
            "Current epoch is:242\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0714 - acc: 0.9451 - val_loss: 1.9546 - val_acc: 0.6739\n",
            "Current epoch is:243\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0536 - acc: 0.9286 - val_loss: 1.8201 - val_acc: 0.6522\n",
            "Current epoch is:244\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0664 - acc: 0.9066 - val_loss: 2.4641 - val_acc: 0.6739\n",
            "Current epoch is:245\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  2.810503860999798\n",
            "Test accuracy:  0.6034482861387318\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0340 - acc: 0.9396 - val_loss: 2.0428 - val_acc: 0.6957\n",
            "Current epoch is:246\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0351 - acc: 0.9451 - val_loss: 1.8612 - val_acc: 0.7174\n",
            "Current epoch is:247\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0344 - acc: 0.9451 - val_loss: 2.0834 - val_acc: 0.6739\n",
            "Current epoch is:248\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0274 - acc: 0.9615 - val_loss: 1.7846 - val_acc: 0.6957\n",
            "Current epoch is:249\n",
            "Train on 182 samples, validate on 46 samples\n",
            "Epoch 1/1\n",
            "182/182 [==============================] - 1s 6ms/step - loss: 0.0714 - acc: 0.9231 - val_loss: 1.5926 - val_acc: 0.6739\n",
            "Current epoch is:250\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.7102500899084683\n",
            "Test accuracy:  0.6896551806351234\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Test loss:  1.7102500899084683\n",
            "Test accuracy:  0.6896551806351234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ILW6reg5SWbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "outputId": "8c6f14f1-87de-44ad-a5cd-236ab8b92b97"
      },
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# Classification Report\n",
        "\n",
        "# make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "################################################################################\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "print(\"\\n###################### Model Performance ############################\")\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('\\nTrain: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "################################################################################\n",
        "print(\"\\n#####################################################################\")\n",
        "# Create the confusion matrix\n",
        "ann_cm = confusion_matrix(y_true = y_test, y_pred = y_pred.round())\n",
        "print(\"\\nOur test confusion matrix yields: \")\n",
        "print(ann_cm)\n",
        "print(\"\\n#####################################################################\")\n",
        "\n",
        "#Classification report\n",
        "ann_report = classification_report(y_test, y_pred.round())\n",
        "print(\"\\nClassfication Report for test:\\n\", ann_report)\n",
        "print(\"\\n#####################################################################\")\n",
        "\n",
        "#Calculate AUC score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "ann_auc = roc_auc_score(y_test, y_pred.round())\n",
        "print(\"\\nOur testing AUC for ann is: \", ann_auc)\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "fpr_ann, tpr_ann, thresholds_ann = roc_curve(y_test, y_pred.round())\n",
        "\n",
        "# Plot AUC \n",
        "plt.figure()\n",
        "plt.plot(fpr_ann, tpr_ann, color='purple', lw=2, label='ANN (area = {:.3f})'.format(ann_auc))\n",
        "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "print(\"\\n#####################################################################\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "###################### Model Performance ############################\n",
            "\n",
            "Train: 0.973, Test: 0.690\n",
            "\n",
            "#####################################################################\n",
            "\n",
            "Our test confusion matrix yields: \n",
            "[[31  5]\n",
            " [13  9]]\n",
            "\n",
            "#####################################################################\n",
            "\n",
            "Classfication Report for test:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.86      0.78        36\n",
            "         1.0       0.64      0.41      0.50        22\n",
            "\n",
            "   micro avg       0.69      0.69      0.69        58\n",
            "   macro avg       0.67      0.64      0.64        58\n",
            "weighted avg       0.68      0.69      0.67        58\n",
            "\n",
            "\n",
            "#####################################################################\n",
            "\n",
            "Our testing AUC for ann is:  0.6351010101010102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFJ5/h/j4R6JBfzwhwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "#####################################################################\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}